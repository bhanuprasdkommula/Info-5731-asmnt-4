{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/unt-iialab/INFO5731_Spring2020/blob/master/Assignments/INFO5731_Assignment_Four.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "USSdXHuqnwv9"
   },
   "source": [
    "# **INFO5731 Assignment Four**\n",
    "\n",
    "In this assignment, you are required to conduct topic modeling, sentiment analysis based on **the dataset you created from assignment three**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YWxodXh5n4xF"
   },
   "source": [
    "# **Question 1: Topic Modeling**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TenBkDJ5n95k"
   },
   "source": [
    "(30 points). This question is designed to help you develop a feel for the way topic modeling works, the connection to the human meanings of documents. Based on the dataset from assignment three, write a python program to **identify the top 10 topics in the dataset**. Before answering this question, please review the materials in lesson 8, especially the code for LDA, LSA, and BERTopic. The following information should be reported:\n",
    "\n",
    "(1) Features (text representation) used for topic modeling.\n",
    "\n",
    "(2) Top 10 clusters for topic modeling.\n",
    "\n",
    "(3) Summarize and describe the topic for each cluster.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "id": "PuFPKhC0m1fd"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Reviews</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>watch titan mani time know everytim watch it s...</td>\n",
       "      <td>postive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>stage curtain open not sinc advent 1995 film b...</td>\n",
       "      <td>postive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>beauti cinemat movi lot classic scenes.also ex...</td>\n",
       "      <td>postive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ah ye film repel leopard dicapro super stardom...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>back 1997 rememb year clinton bank close resea...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Reviews    Rating\n",
       "0  watch titan mani time know everytim watch it s...   postive\n",
       "1  stage curtain open not sinc advent 1995 film b...   postive\n",
       "2  beauti cinemat movi lot classic scenes.also ex...   postive\n",
       "3  ah ye film repel leopard dicapro super stardom...  Negative\n",
       "4  back 1997 rememb year clinton bank close resea...  Negative"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df=pd.read_csv('reviews.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/bhanuprasadkommula/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk   #Cleaning\n",
    "df['Reviews'] = df['Reviews'].str.replace('[^\\w\\s]','')  #Removal of punctuation\n",
    "df['Reviews'] = df['Reviews'].apply(lambda x: \" \".join(x.lower() for x in x.split()))#Lower case\n",
    "from nltk.corpus import stopwords #Removal of stopwords\n",
    "nltk.download('stopwords')\n",
    "stop = stopwords.words('english')\n",
    "df['Reviews'] = df['Reviews'].apply(lambda x: \" \".join(x for x in x.split() if x not in stop))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from gensim import corpora, models\n",
    "import pandas as pd\n",
    "\n",
    "tokenized_reviews = [] \n",
    "\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from gensim import corpora, models\n",
    "import pandas as pd\n",
    "\n",
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "\n",
    "for review_text in pd.Series(df['Reviews']):\n",
    "    tokens = tokenizer.tokenize(review_text)\n",
    "\n",
    "    tokenized_reviews.append(tokens)\n",
    "\n",
    "dictionary = corpora.Dictionary(tokenized_reviews)\n",
    "\n",
    "corpus = [dictionary.doc2bow(tokens) for tokens in tokenized_reviews]\n",
    "\n",
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "\n",
    "for review_text in pd.Series(df['Reviews']):\n",
    "    tokens = tokenizer.tokenize(review_text)\n",
    "\n",
    "    tokenized_reviews.append(tokens)\n",
    "\n",
    "dictionary = corpora.Dictionary(tokenized_reviews)\n",
    "\n",
    "corpus = [dictionary.doc2bow(tokens) for tokens in tokenized_reviews]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim  #LDA model\n",
    "model = gensim.models.ldamodel.LdaModel(corpus, num_topics = 10, id2word = dictionary,passes = 20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, '0.053*\"watch\" + 0.053*\"movi\" + 0.032*\"time\" + 0.016*\"titan\" + 0.016*\"cri\"'), (1, '0.024*\"movi\" + 0.023*\"film\" + 0.021*\"titan\" + 0.021*\"love\" + 0.018*\"time\"'), (2, '0.027*\"movi\" + 0.016*\"time\" + 0.015*\"s\" + 0.015*\"first\" + 0.015*\"thought\"'), (3, '0.021*\"movi\" + 0.021*\"film\" + 0.015*\"titan\" + 0.015*\"stori\" + 0.012*\"watch\"'), (4, '0.020*\"movi\" + 0.020*\"titan\" + 0.020*\"jack\" + 0.015*\"film\" + 0.015*\"rose\"'), (5, '0.029*\"titan\" + 0.021*\"movi\" + 0.021*\"great\" + 0.014*\"year\" + 0.014*\"even\"'), (6, '0.012*\"movi\" + 0.012*\"titan\" + 0.011*\"ship\" + 0.009*\"charact\" + 0.009*\"see\"'), (7, '0.022*\"titan\" + 0.022*\"young\" + 0.022*\"ve\" + 0.011*\"movi\" + 0.011*\"year\"'), (8, '0.054*\"film\" + 0.013*\"s\" + 0.013*\"stori\" + 0.013*\"titan\" + 0.013*\"one\"'), (9, '0.028*\"film\" + 0.021*\"titan\" + 0.016*\"s\" + 0.015*\"one\" + 0.015*\"movi\"')]\n"
     ]
    }
   ],
   "source": [
    "print(model.print_topics(num_topics = 10, num_words = 5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AfpMRCrRwN6Z"
   },
   "source": [
    "# **Question 2: Sentiment Analysis**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1dCQEbDawWCw"
   },
   "source": [
    "(30 points). Sentiment analysis also known as opinion mining is a sub field within Natural Language Processing (NLP) that builds machine learning algorithms to classify a text according to the sentimental polarities of opinions it contains, e.g., positive, negative, neutral. The purpose of this question is to develop a machine learning classifier for sentiment analysis. Based on the dataset from assignment three, write a python program to implement a sentiment classifier and evaluate its performance. Notice: **80% data for training and 20% data for testing**.  \n",
    "\n",
    "(1) Features used for sentiment classification and explain why you select these features.\n",
    "\n",
    "(2) Select two of the supervised learning algorithm from scikit-learn library: https://scikit-learn.org/stable/supervised_learning.html#supervised-learning, to build a sentiment classifier respectively. Note: Cross-validation (5-fold or 10-fold) should be conducted. Here is the reference of cross-validation: https://scikit-learn.org/stable/modules/cross_validation.html.\n",
    "\n",
    "(3) Compare the performance over accuracy, precision, recall, and F1 score for the two algorithms you selected. Here is the reference of how to calculate these metrics: https://towardsdatascience.com/accuracy-precision-recall-or-f1-331fb37c5cb9."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "id": "vATjQNTY8buA"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/bhanuprasadkommula/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Write your code here\n",
    "import nltk\n",
    "df['Reviews'] = df['Reviews'].str.replace('[^\\w\\s]','')  #Removal of punctuation\n",
    "df['Reviews'] = df['Reviews'].apply(lambda x: \" \".join(x.lower() for x in x.split()))#Lower case\n",
    "from nltk.corpus import stopwords #Removal of stopwords\n",
    "nltk.download('stopwords')\n",
    "stop = stopwords.words('english')\n",
    "df['Reviews'] = df['Reviews'].apply(lambda x: \" \".join(x for x in x.split() if x not in stop))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Reviews</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>watch titan mani time know everytim watch stil...</td>\n",
       "      <td>postive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>stage curtain open sinc advent 1995 film brave...</td>\n",
       "      <td>postive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>beauti cinemat movi lot classic scenes.also ex...</td>\n",
       "      <td>postive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ah ye film repel leopard dicapro super stardom...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>back 1997 rememb year clinton bank close resea...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>record breaker see whi even day find anyth tit...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>titan true masterpiec easili one greatest film...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>good lord movi right masterpiec exagger say th...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>lawless enchant riot wondrou total world astou...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>base tragedi span thousand heartbreak true sto...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Reviews    Rating\n",
       "0  watch titan mani time know everytim watch stil...   postive\n",
       "1  stage curtain open sinc advent 1995 film brave...   postive\n",
       "2  beauti cinemat movi lot classic scenes.also ex...   postive\n",
       "3  ah ye film repel leopard dicapro super stardom...  Negative\n",
       "4  back 1997 rememb year clinton bank close resea...  Negative\n",
       "5  record breaker see whi even day find anyth tit...  Negative\n",
       "6  titan true masterpiec easili one greatest film...  Negative\n",
       "7  good lord movi right masterpiec exagger say th...  Negative\n",
       "8  lawless enchant riot wondrou total world astou...  Negative\n",
       "9  base tragedi span thousand heartbreak true sto...  Negative"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tf_idf= TfidfVectorizer(ngram_range=(1,2), max_features=1000)\n",
    "tf_idf.fit(df['Reviews'])\n",
    "x_values =  tf_idf.transform(df['Reviews'])\n",
    "y_values = df['Rating']\n",
    "\n",
    "\n",
    "# Split the training data to training and validating data\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_valid, y_train, y_valid = train_test_split(x_values, y_values, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.5833\n",
      "Recall: 0.5833\n",
      "Precision: 0.5833\n",
      "F-1 score: 0.5833\n",
      "Cross Validation Score: [0.66666667 0.33333333 0.66666667 0.33333333 0.         0.\n",
      " 0.         0.5        0.5        0.5       ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bhanuprasadkommula/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1521: UserWarning: Note that pos_label (set to 'positive') is ignored when average != 'binary' (got 'micro'). You may use labels=[pos_label] to specify a single positive class.\n",
      "  warnings.warn(\n",
      "/Users/bhanuprasadkommula/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1521: UserWarning: Note that pos_label (set to 'positive') is ignored when average != 'binary' (got 'micro'). You may use labels=[pos_label] to specify a single positive class.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "def evaluation(y_pred, y_test):\n",
    "    Accuracy = metrics.accuracy_score(y_pred, y_test)\n",
    "    Recall = metrics.recall_score(y_pred = y_pred, y_true = y_test, pos_label='positive', average='micro') # micro calculates total true positives, false negatives and false positives\n",
    "    Precision = metrics.precision_score(y_pred = y_pred, y_true = y_test, pos_label='positive', average='micro') # micro calculates total true positives, false negatives and false positives\n",
    "    F1 = 2 * (Precision * Recall) / (Precision + Recall) # Formula for F1 Score\n",
    "    print(\"Accuracy: \", Accuracy.round(4))\n",
    "    print(\"Recall:\", Recall.round(4))\n",
    "    print(\"Precision:\", Precision.round(4))\n",
    "    print(\"F-1 score:\", F1.round(4))\n",
    "from sklearn import naive_bayes\n",
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "\n",
    "naive_bayes_implement = naive_bayes.MultinomialNB()\n",
    "\n",
    "naive_bayes_implement.fit(x_train,y_train)\n",
    "\n",
    "y_pred_valid = naive_bayes_implement.predict(x_valid)\n",
    "evaluation(y_pred_valid, y_valid)\n",
    "print(\"Cross Validation Score:\", cross_val_score(naive_bayes_implement, x_valid, y_valid, cv= KFold(10, shuffle=True, random_state = 22)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.5833\n",
      "Recall: 0.5833\n",
      "Precision: 0.5833\n",
      "F-1 score: 0.5833\n",
      "Cross Validation Score: 0.3833\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bhanuprasadkommula/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1521: UserWarning: Note that pos_label (set to 'positive') is ignored when average != 'binary' (got 'micro'). You may use labels=[pos_label] to specify a single positive class.\n",
      "  warnings.warn(\n",
      "/Users/bhanuprasadkommula/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1521: UserWarning: Note that pos_label (set to 'positive') is ignored when average != 'binary' (got 'micro'). You may use labels=[pos_label] to specify a single positive class.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "\n",
    "svm_implement = svm.SVC()\n",
    "\n",
    "svm_implement.fit(x_train,y_train)\n",
    "\n",
    "y_pred_valid = svm_implement.predict(x_valid)\n",
    "evaluation(y_pred_valid, y_valid)\n",
    "print(\"Cross Validation Score:\", cross_val_score(svm_implement, x_valid, y_valid, cv= KFold(10, shuffle=True, random_state = 22)).mean().round(4))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E5mmYIfN8eYV"
   },
   "source": [
    "# **Question 3: House price prediction**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hsi2y4z88ngX"
   },
   "source": [
    "(20 points). You are required to build a **regression** model to predict the house price with 79 explanatory variables describing (almost) every aspect of residential homes. The purpose of this question is to practice regression analysis, an supervised learning model. The training data, testing data, and data description files can be download from canvas. Here is an axample for implementation: https://towardsdatascience.com/linear-regression-in-python-predict-the-bay-areas-home-price-5c91c8378878.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "id": "XfvMKJjIXS5G"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>OverallQual</th>\n",
       "      <th>OverallCond</th>\n",
       "      <th>YearBuilt</th>\n",
       "      <th>YearRemodAdd</th>\n",
       "      <th>MasVnrArea</th>\n",
       "      <th>BsmtFinSF1</th>\n",
       "      <th>...</th>\n",
       "      <th>GarageArea</th>\n",
       "      <th>WoodDeckSF</th>\n",
       "      <th>OpenPorchSF</th>\n",
       "      <th>EnclosedPorch</th>\n",
       "      <th>3SsnPorch</th>\n",
       "      <th>ScreenPorch</th>\n",
       "      <th>PoolArea</th>\n",
       "      <th>MiscVal</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>YrSold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1459.000000</td>\n",
       "      <td>1459.000000</td>\n",
       "      <td>1232.000000</td>\n",
       "      <td>1459.000000</td>\n",
       "      <td>1459.000000</td>\n",
       "      <td>1459.000000</td>\n",
       "      <td>1459.000000</td>\n",
       "      <td>1459.000000</td>\n",
       "      <td>1444.000000</td>\n",
       "      <td>1458.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1458.000000</td>\n",
       "      <td>1459.000000</td>\n",
       "      <td>1459.000000</td>\n",
       "      <td>1459.000000</td>\n",
       "      <td>1459.000000</td>\n",
       "      <td>1459.000000</td>\n",
       "      <td>1459.000000</td>\n",
       "      <td>1459.000000</td>\n",
       "      <td>1459.000000</td>\n",
       "      <td>1459.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2190.000000</td>\n",
       "      <td>57.378341</td>\n",
       "      <td>68.580357</td>\n",
       "      <td>9819.161069</td>\n",
       "      <td>6.078821</td>\n",
       "      <td>5.553804</td>\n",
       "      <td>1971.357779</td>\n",
       "      <td>1983.662783</td>\n",
       "      <td>100.709141</td>\n",
       "      <td>439.203704</td>\n",
       "      <td>...</td>\n",
       "      <td>472.768861</td>\n",
       "      <td>93.174777</td>\n",
       "      <td>48.313914</td>\n",
       "      <td>24.243317</td>\n",
       "      <td>1.794380</td>\n",
       "      <td>17.064428</td>\n",
       "      <td>1.744345</td>\n",
       "      <td>58.167923</td>\n",
       "      <td>6.104181</td>\n",
       "      <td>2007.769705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>421.321334</td>\n",
       "      <td>42.746880</td>\n",
       "      <td>22.376841</td>\n",
       "      <td>4955.517327</td>\n",
       "      <td>1.436812</td>\n",
       "      <td>1.113740</td>\n",
       "      <td>30.390071</td>\n",
       "      <td>21.130467</td>\n",
       "      <td>177.625900</td>\n",
       "      <td>455.268042</td>\n",
       "      <td>...</td>\n",
       "      <td>217.048611</td>\n",
       "      <td>127.744882</td>\n",
       "      <td>68.883364</td>\n",
       "      <td>67.227765</td>\n",
       "      <td>20.207842</td>\n",
       "      <td>56.609763</td>\n",
       "      <td>30.491646</td>\n",
       "      <td>630.806978</td>\n",
       "      <td>2.722432</td>\n",
       "      <td>1.301740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1461.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>1470.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1879.000000</td>\n",
       "      <td>1950.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2006.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1825.500000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>58.000000</td>\n",
       "      <td>7391.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1953.000000</td>\n",
       "      <td>1963.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>318.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2007.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2190.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>67.000000</td>\n",
       "      <td>9399.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1973.000000</td>\n",
       "      <td>1992.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>350.500000</td>\n",
       "      <td>...</td>\n",
       "      <td>480.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>2008.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2554.500000</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>11517.500000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>2001.000000</td>\n",
       "      <td>2004.000000</td>\n",
       "      <td>164.000000</td>\n",
       "      <td>753.500000</td>\n",
       "      <td>...</td>\n",
       "      <td>576.000000</td>\n",
       "      <td>168.000000</td>\n",
       "      <td>72.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>2009.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2919.000000</td>\n",
       "      <td>190.000000</td>\n",
       "      <td>200.000000</td>\n",
       "      <td>56600.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>2010.000000</td>\n",
       "      <td>2010.000000</td>\n",
       "      <td>1290.000000</td>\n",
       "      <td>4010.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1488.000000</td>\n",
       "      <td>1424.000000</td>\n",
       "      <td>742.000000</td>\n",
       "      <td>1012.000000</td>\n",
       "      <td>360.000000</td>\n",
       "      <td>576.000000</td>\n",
       "      <td>800.000000</td>\n",
       "      <td>17000.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>2010.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 37 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                Id   MSSubClass  LotFrontage       LotArea  OverallQual  \\\n",
       "count  1459.000000  1459.000000  1232.000000   1459.000000  1459.000000   \n",
       "mean   2190.000000    57.378341    68.580357   9819.161069     6.078821   \n",
       "std     421.321334    42.746880    22.376841   4955.517327     1.436812   \n",
       "min    1461.000000    20.000000    21.000000   1470.000000     1.000000   \n",
       "25%    1825.500000    20.000000    58.000000   7391.000000     5.000000   \n",
       "50%    2190.000000    50.000000    67.000000   9399.000000     6.000000   \n",
       "75%    2554.500000    70.000000    80.000000  11517.500000     7.000000   \n",
       "max    2919.000000   190.000000   200.000000  56600.000000    10.000000   \n",
       "\n",
       "       OverallCond    YearBuilt  YearRemodAdd   MasVnrArea   BsmtFinSF1  ...  \\\n",
       "count  1459.000000  1459.000000   1459.000000  1444.000000  1458.000000  ...   \n",
       "mean      5.553804  1971.357779   1983.662783   100.709141   439.203704  ...   \n",
       "std       1.113740    30.390071     21.130467   177.625900   455.268042  ...   \n",
       "min       1.000000  1879.000000   1950.000000     0.000000     0.000000  ...   \n",
       "25%       5.000000  1953.000000   1963.000000     0.000000     0.000000  ...   \n",
       "50%       5.000000  1973.000000   1992.000000     0.000000   350.500000  ...   \n",
       "75%       6.000000  2001.000000   2004.000000   164.000000   753.500000  ...   \n",
       "max       9.000000  2010.000000   2010.000000  1290.000000  4010.000000  ...   \n",
       "\n",
       "        GarageArea   WoodDeckSF  OpenPorchSF  EnclosedPorch    3SsnPorch  \\\n",
       "count  1458.000000  1459.000000  1459.000000    1459.000000  1459.000000   \n",
       "mean    472.768861    93.174777    48.313914      24.243317     1.794380   \n",
       "std     217.048611   127.744882    68.883364      67.227765    20.207842   \n",
       "min       0.000000     0.000000     0.000000       0.000000     0.000000   \n",
       "25%     318.000000     0.000000     0.000000       0.000000     0.000000   \n",
       "50%     480.000000     0.000000    28.000000       0.000000     0.000000   \n",
       "75%     576.000000   168.000000    72.000000       0.000000     0.000000   \n",
       "max    1488.000000  1424.000000   742.000000    1012.000000   360.000000   \n",
       "\n",
       "       ScreenPorch     PoolArea       MiscVal       MoSold       YrSold  \n",
       "count  1459.000000  1459.000000   1459.000000  1459.000000  1459.000000  \n",
       "mean     17.064428     1.744345     58.167923     6.104181  2007.769705  \n",
       "std      56.609763    30.491646    630.806978     2.722432     1.301740  \n",
       "min       0.000000     0.000000      0.000000     1.000000  2006.000000  \n",
       "25%       0.000000     0.000000      0.000000     4.000000  2007.000000  \n",
       "50%       0.000000     0.000000      0.000000     6.000000  2008.000000  \n",
       "75%       0.000000     0.000000      0.000000     8.000000  2009.000000  \n",
       "max     576.000000   800.000000  17000.000000    12.000000  2010.000000  \n",
       "\n",
       "[8 rows x 37 columns]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Write your code here\n",
    "import pandas as pd\n",
    "df_train = pd.read_csv(\"test.csv\")\n",
    "df_test = pd.read_csv(\"train.csv\")\n",
    "\n",
    "df_train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1459 entries, 0 to 1458\n",
      "Data columns (total 80 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   Id             1459 non-null   int64  \n",
      " 1   MSSubClass     1459 non-null   int64  \n",
      " 2   MSZoning       1455 non-null   object \n",
      " 3   LotFrontage    1232 non-null   float64\n",
      " 4   LotArea        1459 non-null   int64  \n",
      " 5   Street         1459 non-null   object \n",
      " 6   Alley          107 non-null    object \n",
      " 7   LotShape       1459 non-null   object \n",
      " 8   LandContour    1459 non-null   object \n",
      " 9   Utilities      1457 non-null   object \n",
      " 10  LotConfig      1459 non-null   object \n",
      " 11  LandSlope      1459 non-null   object \n",
      " 12  Neighborhood   1459 non-null   object \n",
      " 13  Condition1     1459 non-null   object \n",
      " 14  Condition2     1459 non-null   object \n",
      " 15  BldgType       1459 non-null   object \n",
      " 16  HouseStyle     1459 non-null   object \n",
      " 17  OverallQual    1459 non-null   int64  \n",
      " 18  OverallCond    1459 non-null   int64  \n",
      " 19  YearBuilt      1459 non-null   int64  \n",
      " 20  YearRemodAdd   1459 non-null   int64  \n",
      " 21  RoofStyle      1459 non-null   object \n",
      " 22  RoofMatl       1459 non-null   object \n",
      " 23  Exterior1st    1458 non-null   object \n",
      " 24  Exterior2nd    1458 non-null   object \n",
      " 25  MasVnrType     565 non-null    object \n",
      " 26  MasVnrArea     1444 non-null   float64\n",
      " 27  ExterQual      1459 non-null   object \n",
      " 28  ExterCond      1459 non-null   object \n",
      " 29  Foundation     1459 non-null   object \n",
      " 30  BsmtQual       1415 non-null   object \n",
      " 31  BsmtCond       1414 non-null   object \n",
      " 32  BsmtExposure   1415 non-null   object \n",
      " 33  BsmtFinType1   1417 non-null   object \n",
      " 34  BsmtFinSF1     1458 non-null   float64\n",
      " 35  BsmtFinType2   1417 non-null   object \n",
      " 36  BsmtFinSF2     1458 non-null   float64\n",
      " 37  BsmtUnfSF      1458 non-null   float64\n",
      " 38  TotalBsmtSF    1458 non-null   float64\n",
      " 39  Heating        1459 non-null   object \n",
      " 40  HeatingQC      1459 non-null   object \n",
      " 41  CentralAir     1459 non-null   object \n",
      " 42  Electrical     1459 non-null   object \n",
      " 43  1stFlrSF       1459 non-null   int64  \n",
      " 44  2ndFlrSF       1459 non-null   int64  \n",
      " 45  LowQualFinSF   1459 non-null   int64  \n",
      " 46  GrLivArea      1459 non-null   int64  \n",
      " 47  BsmtFullBath   1457 non-null   float64\n",
      " 48  BsmtHalfBath   1457 non-null   float64\n",
      " 49  FullBath       1459 non-null   int64  \n",
      " 50  HalfBath       1459 non-null   int64  \n",
      " 51  BedroomAbvGr   1459 non-null   int64  \n",
      " 52  KitchenAbvGr   1459 non-null   int64  \n",
      " 53  KitchenQual    1458 non-null   object \n",
      " 54  TotRmsAbvGrd   1459 non-null   int64  \n",
      " 55  Functional     1457 non-null   object \n",
      " 56  Fireplaces     1459 non-null   int64  \n",
      " 57  FireplaceQu    729 non-null    object \n",
      " 58  GarageType     1383 non-null   object \n",
      " 59  GarageYrBlt    1381 non-null   float64\n",
      " 60  GarageFinish   1381 non-null   object \n",
      " 61  GarageCars     1458 non-null   float64\n",
      " 62  GarageArea     1458 non-null   float64\n",
      " 63  GarageQual     1381 non-null   object \n",
      " 64  GarageCond     1381 non-null   object \n",
      " 65  PavedDrive     1459 non-null   object \n",
      " 66  WoodDeckSF     1459 non-null   int64  \n",
      " 67  OpenPorchSF    1459 non-null   int64  \n",
      " 68  EnclosedPorch  1459 non-null   int64  \n",
      " 69  3SsnPorch      1459 non-null   int64  \n",
      " 70  ScreenPorch    1459 non-null   int64  \n",
      " 71  PoolArea       1459 non-null   int64  \n",
      " 72  PoolQC         3 non-null      object \n",
      " 73  Fence          290 non-null    object \n",
      " 74  MiscFeature    51 non-null     object \n",
      " 75  MiscVal        1459 non-null   int64  \n",
      " 76  MoSold         1459 non-null   int64  \n",
      " 77  YrSold         1459 non-null   int64  \n",
      " 78  SaleType       1458 non-null   object \n",
      " 79  SaleCondition  1459 non-null   object \n",
      "dtypes: float64(11), int64(26), object(43)\n",
      "memory usage: 912.0+ KB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>OverallQual</th>\n",
       "      <th>OverallCond</th>\n",
       "      <th>YearBuilt</th>\n",
       "      <th>YearRemodAdd</th>\n",
       "      <th>MasVnrArea</th>\n",
       "      <th>BsmtFinSF1</th>\n",
       "      <th>...</th>\n",
       "      <th>WoodDeckSF</th>\n",
       "      <th>OpenPorchSF</th>\n",
       "      <th>EnclosedPorch</th>\n",
       "      <th>3SsnPorch</th>\n",
       "      <th>ScreenPorch</th>\n",
       "      <th>PoolArea</th>\n",
       "      <th>MiscVal</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>YrSold</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1201.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1452.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>730.500000</td>\n",
       "      <td>56.897260</td>\n",
       "      <td>70.049958</td>\n",
       "      <td>10516.828082</td>\n",
       "      <td>6.099315</td>\n",
       "      <td>5.575342</td>\n",
       "      <td>1971.267808</td>\n",
       "      <td>1984.865753</td>\n",
       "      <td>103.685262</td>\n",
       "      <td>443.639726</td>\n",
       "      <td>...</td>\n",
       "      <td>94.244521</td>\n",
       "      <td>46.660274</td>\n",
       "      <td>21.954110</td>\n",
       "      <td>3.409589</td>\n",
       "      <td>15.060959</td>\n",
       "      <td>2.758904</td>\n",
       "      <td>43.489041</td>\n",
       "      <td>6.321918</td>\n",
       "      <td>2007.815753</td>\n",
       "      <td>180921.195890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>421.610009</td>\n",
       "      <td>42.300571</td>\n",
       "      <td>24.284752</td>\n",
       "      <td>9981.264932</td>\n",
       "      <td>1.382997</td>\n",
       "      <td>1.112799</td>\n",
       "      <td>30.202904</td>\n",
       "      <td>20.645407</td>\n",
       "      <td>181.066207</td>\n",
       "      <td>456.098091</td>\n",
       "      <td>...</td>\n",
       "      <td>125.338794</td>\n",
       "      <td>66.256028</td>\n",
       "      <td>61.119149</td>\n",
       "      <td>29.317331</td>\n",
       "      <td>55.757415</td>\n",
       "      <td>40.177307</td>\n",
       "      <td>496.123024</td>\n",
       "      <td>2.703626</td>\n",
       "      <td>1.328095</td>\n",
       "      <td>79442.502883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>1300.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1872.000000</td>\n",
       "      <td>1950.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2006.000000</td>\n",
       "      <td>34900.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>365.750000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>59.000000</td>\n",
       "      <td>7553.500000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1954.000000</td>\n",
       "      <td>1967.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>2007.000000</td>\n",
       "      <td>129975.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>730.500000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>69.000000</td>\n",
       "      <td>9478.500000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1973.000000</td>\n",
       "      <td>1994.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>383.500000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>2008.000000</td>\n",
       "      <td>163000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1095.250000</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>11601.500000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2004.000000</td>\n",
       "      <td>166.000000</td>\n",
       "      <td>712.250000</td>\n",
       "      <td>...</td>\n",
       "      <td>168.000000</td>\n",
       "      <td>68.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>2009.000000</td>\n",
       "      <td>214000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1460.000000</td>\n",
       "      <td>190.000000</td>\n",
       "      <td>313.000000</td>\n",
       "      <td>215245.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>2010.000000</td>\n",
       "      <td>2010.000000</td>\n",
       "      <td>1600.000000</td>\n",
       "      <td>5644.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>857.000000</td>\n",
       "      <td>547.000000</td>\n",
       "      <td>552.000000</td>\n",
       "      <td>508.000000</td>\n",
       "      <td>480.000000</td>\n",
       "      <td>738.000000</td>\n",
       "      <td>15500.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>2010.000000</td>\n",
       "      <td>755000.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 38 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                Id   MSSubClass  LotFrontage        LotArea  OverallQual  \\\n",
       "count  1460.000000  1460.000000  1201.000000    1460.000000  1460.000000   \n",
       "mean    730.500000    56.897260    70.049958   10516.828082     6.099315   \n",
       "std     421.610009    42.300571    24.284752    9981.264932     1.382997   \n",
       "min       1.000000    20.000000    21.000000    1300.000000     1.000000   \n",
       "25%     365.750000    20.000000    59.000000    7553.500000     5.000000   \n",
       "50%     730.500000    50.000000    69.000000    9478.500000     6.000000   \n",
       "75%    1095.250000    70.000000    80.000000   11601.500000     7.000000   \n",
       "max    1460.000000   190.000000   313.000000  215245.000000    10.000000   \n",
       "\n",
       "       OverallCond    YearBuilt  YearRemodAdd   MasVnrArea   BsmtFinSF1  ...  \\\n",
       "count  1460.000000  1460.000000   1460.000000  1452.000000  1460.000000  ...   \n",
       "mean      5.575342  1971.267808   1984.865753   103.685262   443.639726  ...   \n",
       "std       1.112799    30.202904     20.645407   181.066207   456.098091  ...   \n",
       "min       1.000000  1872.000000   1950.000000     0.000000     0.000000  ...   \n",
       "25%       5.000000  1954.000000   1967.000000     0.000000     0.000000  ...   \n",
       "50%       5.000000  1973.000000   1994.000000     0.000000   383.500000  ...   \n",
       "75%       6.000000  2000.000000   2004.000000   166.000000   712.250000  ...   \n",
       "max       9.000000  2010.000000   2010.000000  1600.000000  5644.000000  ...   \n",
       "\n",
       "        WoodDeckSF  OpenPorchSF  EnclosedPorch    3SsnPorch  ScreenPorch  \\\n",
       "count  1460.000000  1460.000000    1460.000000  1460.000000  1460.000000   \n",
       "mean     94.244521    46.660274      21.954110     3.409589    15.060959   \n",
       "std     125.338794    66.256028      61.119149    29.317331    55.757415   \n",
       "min       0.000000     0.000000       0.000000     0.000000     0.000000   \n",
       "25%       0.000000     0.000000       0.000000     0.000000     0.000000   \n",
       "50%       0.000000    25.000000       0.000000     0.000000     0.000000   \n",
       "75%     168.000000    68.000000       0.000000     0.000000     0.000000   \n",
       "max     857.000000   547.000000     552.000000   508.000000   480.000000   \n",
       "\n",
       "          PoolArea       MiscVal       MoSold       YrSold      SalePrice  \n",
       "count  1460.000000   1460.000000  1460.000000  1460.000000    1460.000000  \n",
       "mean      2.758904     43.489041     6.321918  2007.815753  180921.195890  \n",
       "std      40.177307    496.123024     2.703626     1.328095   79442.502883  \n",
       "min       0.000000      0.000000     1.000000  2006.000000   34900.000000  \n",
       "25%       0.000000      0.000000     5.000000  2007.000000  129975.000000  \n",
       "50%       0.000000      0.000000     6.000000  2008.000000  163000.000000  \n",
       "75%       0.000000      0.000000     8.000000  2009.000000  214000.000000  \n",
       "max     738.000000  15500.000000    12.000000  2010.000000  755000.000000  \n",
       "\n",
       "[8 rows x 38 columns]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.info()\n",
    "df_test.describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import numpy as np\n",
    "\n",
    "df_train_processed = df_train.select_dtypes(include=['number']).interpolate().dropna()\n",
    "df_test_processed = df_test.select_dtypes(include=['number']).interpolate().dropna()\n",
    "\n",
    "x_training_data = df_test_processed.drop(['SalePrice', 'Id'], axis=1)\n",
    "y_training_data = np.log(df_test_processed.SalePrice)\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x_training_data, y_training_data, random_state=21, test_size=0.2\n",
    ")\n",
    "\n",
    "regression = LinearRegression()\n",
    "regression.fit(x_train, y_train)\n",
    "\n",
    "y_pred = regression.predict(x_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression R squared\": 0.8493\n"
     ]
    }
   ],
   "source": [
    "print('Linear Regression R squared\": %.4f' % regression.score(x_test, y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "195747.2801595368\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error\n",
    "lin_R = mean_squared_error(np.exp(y_pred), y_test)\n",
    "lin_reg = np.sqrt(lin_R)\n",
    "print(lin_reg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted Prices</th>\n",
       "      <th>Actual Prices</th>\n",
       "      <th>Percentage Difference</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>880</th>\n",
       "      <td>156677.762126</td>\n",
       "      <td>157000.0</td>\n",
       "      <td>0.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>605</th>\n",
       "      <td>229973.921577</td>\n",
       "      <td>205000.0</td>\n",
       "      <td>12.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1166</th>\n",
       "      <td>245358.948864</td>\n",
       "      <td>245350.0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>216</th>\n",
       "      <td>218109.586021</td>\n",
       "      <td>210000.0</td>\n",
       "      <td>3.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>970</th>\n",
       "      <td>86909.329260</td>\n",
       "      <td>135000.0</td>\n",
       "      <td>35.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>218</th>\n",
       "      <td>231419.797074</td>\n",
       "      <td>311500.0</td>\n",
       "      <td>25.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1228</th>\n",
       "      <td>311321.804719</td>\n",
       "      <td>367294.0</td>\n",
       "      <td>15.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1007</th>\n",
       "      <td>93234.996099</td>\n",
       "      <td>88000.0</td>\n",
       "      <td>5.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>575</th>\n",
       "      <td>109041.447359</td>\n",
       "      <td>118500.0</td>\n",
       "      <td>7.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>599</th>\n",
       "      <td>172431.414374</td>\n",
       "      <td>151000.0</td>\n",
       "      <td>14.19</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>292 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Predicted Prices  Actual Prices  Percentage Difference\n",
       "880      156677.762126       157000.0                   0.21\n",
       "605      229973.921577       205000.0                  12.18\n",
       "1166     245358.948864       245350.0                   0.00\n",
       "216      218109.586021       210000.0                   3.86\n",
       "970       86909.329260       135000.0                  35.62\n",
       "...                ...            ...                    ...\n",
       "218      231419.797074       311500.0                  25.71\n",
       "1228     311321.804719       367294.0                  15.24\n",
       "1007      93234.996099        88000.0                   5.95\n",
       "575      109041.447359       118500.0                   7.98\n",
       "599      172431.414374       151000.0                  14.19\n",
       "\n",
       "[292 rows x 3 columns]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = {\"Predicted Prices\":np.exp(y_pred),\"Actual Prices\":np.exp(y_test)}\n",
    "df_val = pd.DataFrame(results)\n",
    "df_val[\"Percentage Difference\"] = round(abs((df_val[\"Predicted Prices\"] - df_val[\"Actual Prices\"]) / df_val[\"Actual Prices\"]) * 100,2)\n",
    "df_val\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_BbswDvnEX-k"
   },
   "source": [
    "# **Question 4: Using Pre-trained LLMs**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xKwKTnW1EX-k"
   },
   "source": [
    "(20 points)\n",
    "Utilize a **pre-trained Large Language Model (LLM) from the Hugging Face Repository** for your specific task using the data collected in Assignment 3. After creating an account on Hugging Face (https://huggingface.co/), choose a relevant LLM from their repository, such as GPT-3, BERT, or RoBERTa or any Meta based text analysis model. Provide a brief description of the selected LLM, including its original sources, significant parameters, and any task-specific fine-tuning if applied.\n",
    "\n",
    "Perform a detailed analysis of the LLM's performance on your task, including key metrics, strengths, and limitations. Additionally, discuss any challenges encountered during the implementation and potential strategies for improvement. This will enable a comprehensive understanding of the chosen LLM's applicability and effectiveness for the given task.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.0000\n",
      "Precision: 0.0000\n",
      "Recall: 0.0000\n",
      "F1 Score: 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bhanuprasadkommula/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/bhanuprasadkommula/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/bhanuprasadkommula/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1757: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import torch\n",
    "\n",
    "df = pd.read_csv('reviews.csv')\n",
    "\n",
    "reviews_data = df['Reviews'].values\n",
    "sentiments_data = df['Rating'].apply(lambda x: 1 if x == 'positive' else 0).values\n",
    "\n",
    "X_train_data, X_test_data, y_train_data, y_test_data = train_test_split(\n",
    "    reviews_data, sentiments_data, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "X_train_dev_data, _, y_train_dev_data, _ = train_test_split(\n",
    "    X_train_data, y_train_data, train_size=0.1, random_state=42\n",
    ")\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=2)\n",
    "\n",
    "X_train_tokens = tokenizer(\n",
    "    list(X_train_dev_data),\n",
    "    padding=True,\n",
    "    truncation=True,\n",
    "    return_tensors='pt',\n",
    "    max_length=256\n",
    ")\n",
    "X_test_tokens = tokenizer(\n",
    "    list(X_test_data),\n",
    "    padding=True,\n",
    "    truncation=True,\n",
    "    return_tensors='pt',\n",
    "    max_length=256\n",
    ")\n",
    "\n",
    "train_dataset = TensorDataset(\n",
    "    X_train_tokens['input_ids'],\n",
    "    X_train_tokens['attention_mask'],\n",
    "    torch.tensor(y_train_dev_data, dtype=torch.long)\n",
    ")\n",
    "test_dataset = TensorDataset(\n",
    "    X_test_tokens['input_ids'],\n",
    "    X_test_tokens['attention_mask'],\n",
    "    torch.tensor(y_test_data, dtype=torch.long)\n",
    ")\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=8, shuffle=False)\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=2e-5)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "num_epochs = 1\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    for batch in train_dataloader:\n",
    "        input_ids, attention_mask, labels = batch\n",
    "        input_ids, attention_mask, labels = input_ids.to(device), attention_mask.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
    "        loss = outputs.loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "model.eval()\n",
    "predictions = []\n",
    "with torch.no_grad():\n",
    "    for batch in test_dataloader:\n",
    "        input_ids, attention_mask, labels = batch\n",
    "        input_ids, attention_mask, labels = input_ids.to(device), attention_mask.to(device), labels.to(device)\n",
    "\n",
    "        outputs = model(input_ids, attention_mask=attention_mask)\n",
    "        logits = outputs.logits\n",
    "        probabilities = torch.nn.functional.softmax(logits, dim=1)\n",
    "        predicted_labels = torch.argmax(probabilities, dim=1)\n",
    "        predictions.extend(predicted_labels.cpu().numpy())\n",
    "\n",
    "accuracy = accuracy_score(y_test_data, predictions)\n",
    "precision = precision_score(y_test_data, predictions)\n",
    "recall = recall_score(y_test_data, predictions)\n",
    "f1 = f1_score(y_test_data, predictions)\n",
    "\n",
    "print(f'Accuracy: {accuracy:.4f}')\n",
    "print(f'Precision: {precision:.4f}')\n",
    "print(f'Recall: {recall:.4f}')\n",
    "print(f'F1 Score: {f1:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
